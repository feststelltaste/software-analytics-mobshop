{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# timeseries\n",
    "\n",
    "**Working with timeseries in pandas is a fullfilling to work with time-based data.**\n",
    "\n",
    "This Cheatbook (Cheatsheet + Notebook) introduces you to the core functionality when working with pandas' time series / date functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* [API Reference](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just pandas' time data types is fun. Pandas provides intuitive ways for working with time data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single time objects\n",
    "Let's create some Timestamps / point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Timestamp(\"today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can put in some standard date formats. Pandas' will convert them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_years_dinner = pd.Timestamp(\"2020-01-01 19:00\")\n",
    "new_years_dinner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create relative time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_needed_to_sober_up = pd.Timedelta(\"1 day\")\n",
    "time_needed_to_sober_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do calculations with thos objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completely_sober = new_years_dinner + time_needed_to_sober_up\n",
    "completely_sober"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "We can work with a list of time-based data, too. Here we use pandas' `date_range` method to create such a list (with `m` for end of months)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(\n",
    "            pd.date_range(\"2020-03-01\", periods=5, freq=\"m\"),\n",
    "            columns=[\"day\"]\n",
    "        )\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we calculate with time in a similar way as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[\"day_after_tomorrow\"] = dates['day'] + pd.Timedelta(\"2 days\")\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTimeProperties object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially the `DateTimeProperties` object contains time related data as attributes or methods that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_properties = dates['day'].dt\n",
    "dt_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look the some of the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is just for demonstration purposes and not needed in an analysis\n",
    "[x for x in dir(dt_properties) if not x.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can e.g. call the method `day_name()` on a date time series to get the name of the day for a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_properties.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Series\n",
    "Let's work with some real data (or at least a part of it). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Scenario\n",
    "The following dataset is an excerpt from a change log of a software. We want to take a look at which hour of the day the changes are made to the software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read in time-based datasets as any other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log = pd.read_csv(\"../datasets/change_history.csv\")\n",
    "change_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, if we import a dataset like this, the time data will be of a simple object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to convert that data first into a time-based data type with pandas' `to_datetime()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log['timestamp'] = pd.to_datetime(change_log['timestamp'])\n",
    "change_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to see at whick hour of the day most changes were done. We can use the same strategies to get more detailed information like in the previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log['hour'] = change_log['timestamp'].dt.hour\n",
    "change_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simply count the number of changes per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_hour = change_log['hour'].value_counts(sort=False)\n",
    "changes_per_hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a little bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_hour.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first glance, this looks pretty fine. But there is a problem: Missing data. E.g. at 3am and 5am, there weren't any changes.\n",
    "\n",
    "We can handle this by using the more advanced `resample` functionality of pandas. This allows us to determine at which frequency we summarize time-based data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second try: resampling time\n",
    "For this, we create a time series Dataframe from the dataset again. This time, we import the dataset by additionally using the `parse_dates` keyword and the number of the column that contains dates. This would lead to an converted date column from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log = pd.read_csv(\"../datasets/change_history.csv\", parse_dates=[0], index_col=0)\n",
    "change_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log['changes'] = 1\n",
    "change_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to apply the `resample` function on it with the information that we want to group our data hourly. We also have to decided what we want to do with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_changes = change_log.resample(\"h\").count()\n",
    "hourly_changes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_changes['hour'] = hourly_changes.index.hour\n",
    "hourly_changes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_hour = hourly_changes.groupby(\"hour\").sum()\n",
    "changes_per_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_per_hour.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display progressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_changes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_changes = hourly_changes[['changes']].cumsum()\n",
    "accumulated_changes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_changes.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping time and data\n",
    "So far, we did group only on time-based data. But what if we want, e.g., group the weekly changes by each developer? Let's do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we read in the dataset that we already know. We only let pandas parse the timestamp information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log = pd.read_csv(\"../datasets/change_history.csv\", parse_dates=[0])\n",
    "change_log.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this scenario, we also need some developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs = pd.Series([\"Alice\", \"Bob\", \"John\", \"Steve\", \"Yvonne\"])\n",
    "devs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some artificial ones to the changes and also mark each change with a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log['dev'] = devs.sample(len(change_log), replace=True).values\n",
    "change_log['changes'] = 1\n",
    "change_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we want to group the changes per week per developer to find out the most active developer of the week (if this makes sense is up to you to find out ;-).\n",
    "\n",
    "For this, we use `groupby` with a pandas `Grouper`. With the `Grouper`, we can say which column we want to group at which frequency (seconds, minutes, ... , years and so on). In our case: weekly. Additionally, we want to track which developer did how many weekly changes. So we take developers also in the list with the relevant information that should be grouped and sum up the changes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_changes_per_dev = \\\n",
    "    change_log.groupby([\n",
    "        pd.Grouper(key='timestamp', freq='w'),\n",
    "        'dev']) \\\n",
    "    .sum()\n",
    "weekly_changes_per_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give as a Dataframe which lists the number of changes per week for each developers. We sort this list to get a kind of \"most active developer per week list\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_changes_per_dev.sort_values(\n",
    "    by=['timestamp', 'changes'],\n",
    "    ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This Cheatbook guided you through several time series use cases. I hope you find this a good starting point for your own data analysis with time-based data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
